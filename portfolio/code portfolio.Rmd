---
title: "Code Porfolio"
author: "Mengtian Guo"
date: "January 22, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##DATA IMPORT
```{r}
#library(readr)
#ozone <- read_csv("data/hourly_44201_2014.csv", 
#+                   col_types = "ccccinnccccccncnncccccc")
#names(ozone) <- make.names(names(ozone)) #remove spaces in column headers

```


##DATA WRANGLING - TIDY DATA
```{r}
library(tidyverse)

```

###DATA IMPORT - PARSING A VECTOR

```{r}
parse_integer(c("1", "231", ".", "456"), na = ".")
#> [1]   1 231  NA 456
parse_number("1,23", locale = locale(decimal_mark = ","))
#> [1] 1.23
parse_number("20%")
#> [1] 20
parse_number("It cost $123.45")
#> [1] 123

parse_datetime("2010-10-01T2010")
#> [1] "2010-10-01 20:10:00 UTC"
parse_datetime("20101010")
#> [1] "2010-10-10 UTC"

```

###GATHERING - "RELATIONAL DATABASE"

```{r}
table4a
#> # A tibble: 3 x 3
#>   country     `1999` `2000`
#> * <chr>        <int>  <int>
#> 1 Afghanistan    745   2666
#> 2 Brazil       37737  80488
#> 3 China       212258 213766

tidy4a <- table4a %>% 
  gather(`1999`, `2000`, key = "year", value = "cases")
tidy4b <- table4b %>% 
  gather(`1999`, `2000`, key = "year", value = "population")
left_join(tidy4a, tidy4b)
#> Joining, by = c("country", "year")
#> # A tibble: 6 x 4
#>   country     year   cases population
#>   <chr>       <chr>  <int>      <int>
#> 1 Afghanistan 1999     745   19987071
#> 2 Brazil      1999   37737  172006362
#> 3 China       1999  212258 1272915272
#> 4 Afghanistan 2000    2666   20595360
#> 5 Brazil      2000   80488  174504898
#> 6 China       2000  213766 1280428583

```


###SPREADING - "RELATIONAL DATABASE" (OPPOSITE TO GATHERING) 
```{r}
table2
#> # A tibble: 12 x 4
#>   country      year type           count
#>   <chr>       <int> <chr>          <int>
#> 1 Afghanistan  1999 cases            745
#> 2 Afghanistan  1999 population  19987071
#> 3 Afghanistan  2000 cases           2666
#> 4 Afghanistan  2000 population  20595360
#> 5 Brazil       1999 cases          37737
#> 6 Brazil       1999 population 172006362
#> # . with 6 more rows

table2 %>%
    spread(key = type, value = count)
#> # A tibble: 6 x 4
#>   country      year  cases population
#>   <chr>       <int>  <int>      <int>
#> 1 Afghanistan  1999    745   19987071
#> 2 Afghanistan  2000   2666   20595360
#> 3 Brazil       1999  37737  172006362
#> 4 Brazil       2000  80488  174504898
#> 5 China        1999 212258 1272915272
#> 6 China        2000 213766 1280428583

```

###SEPARATING - "RELATIONAL DATABASE" 
```{r}
table3
#> # A tibble: 6 x 3
#>   country      year rate             
#> * <chr>       <int> <chr>            
#> 1 Afghanistan  1999 745/19987071     
#> 2 Afghanistan  2000 2666/20595360    
#> 3 Brazil       1999 37737/172006362  
#> 4 Brazil       2000 80488/174504898  
#> 5 China        1999 212258/1272915272
#> 6 China        2000 213766/1280428583

table3 %>% 
  separate(rate, into = c("cases", "population"), convert = TRUE)
#> # A tibble: 6 x 4
#>   country      year  cases population
#>   <chr>       <int>  <int>      <int>
#> 1 Afghanistan  1999    745   19987071
#> 2 Afghanistan  2000   2666   20595360
#> 3 Brazil       1999  37737  172006362
#> 4 Brazil       2000  80488  174504898
#> 5 China        1999 212258 1272915272
#> 6 China        2000 213766 1280428583

```

###UNITING - "RELATIONAL DATABASE" (OPPOSITE TO SEPARATING) 
```{r}
table5 %>% 
  unite(new, century, year)
#> # A tibble: 6 x 3
#>   country     new   rate             
#>   <chr>       <chr> <chr>            
#> 1 Afghanistan 19_99 745/19987071     
#> 2 Afghanistan 20_00 2666/20595360    
#> 3 Brazil      19_99 37737/172006362  
#> 4 Brazil      20_00 80488/174504898  
#> 5 China       19_99 212258/1272915272
#> 6 China       20_00 213766/1280428583

table5 %>% 
  unite(new, century, year)
#> # A tibble: 6 x 3
#>   country     new   rate             
#>   <chr>       <chr> <chr>            
#> 1 Afghanistan 1999  745/19987071     
#> 2 Afghanistan 2000  2666/20595360    
#> 3 Brazil      1999  37737/172006362  
#> 4 Brazil      2000  80488/174504898  
#> 5 China       1999  212258/1272915272
#> 6 China       2000  213766/1280428583

```

###MISSING VALUES: filled in with NA, replaced by last observation 
```{r}
stocks <- tibble(
  year   = c(2015, 2015, 2015, 2015, 2016, 2016, 2016),
  qtr    = c(   1,    2,    3,    4,    2,    3,    4),
  return = c(1.88, 0.59, 0.35,   NA, 0.92, 0.17, 2.66)
)

stocks %>% 
  complete(year, qtr)
#> # A tibble: 8 x 3
#>    year   qtr return
#>   <dbl> <dbl>  <dbl>
#> 1  2015     1   1.88
#> 2  2015     2   0.59
#> 3  2015     3   0.35
#> 4  2015     4  NA   
#> 5  2016     1  NA   
#> 6  2016     2   0.92
#> # . with 2 more rows

treatment <- tribble(
  ~ person,           ~ treatment, ~response,
  "Derrick Whitmore", 1,           7,
  NA,                 2,           10,
  NA,                 3,           9,
  "Katherine Burke",  1,           4
)

treatment %>% 
  fill(person)
#> # A tibble: 4 x 3
#>   person           treatment response
#>   <chr>                <dbl>    <dbl>
#> 1 Derrick Whitmore         1        7
#> 2 Derrick Whitmore         2       10
#> 3 Derrick Whitmore         3        9
#> 4 Katherine Burke          1        4

```

##DATA TRANSFORMATION: dplyr PACKAGE WITHIN tidyverse
###DATASET
```{r}
library(tidyverse)
library(nycflights13)

flights
#> # A tibble: 336,776 x 19
#>    year month   day dep_time sched_dep_time dep_delay arr_time
#>   <int> <int> <int>    <int>          <int>     <dbl>    <int>
#> 1  2013     1     1      517            515         2      830
#> 2  2013     1     1      533            529         4      850
#> 3  2013     1     1      542            540         2      923
#> 4  2013     1     1      544            545        -1     1004
#> 5  2013     1     1      554            600        -6      812
#> 6  2013     1     1      554            558        -4      740
#> # . with 3.368e+05 more rows, and 12 more variables: sched_arr_time <int>,
#> #   arr_delay <dbl>, carrier <chr>, flight <int>, tailnum <chr>,
#> #   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,
#> #   minute <dbl>, time_hour <dttm>

#Tibbles are data frames, but slightly tweaked to work better in the tidyverse.#

```

###FILTER TO SPECIFIC CONDITIONS OF COLUMN
```{r}
(jan1 = filter(flights, month == 1, day == 1))
#> # A tibble: 842 x 19
#>    year month   day dep_time sched_dep_time dep_delay arr_time
#>   <int> <int> <int>    <int>          <int>     <dbl>    <int>
#> 1  2013     1     1      517            515         2      830
#> 2  2013     1     1      533            529         4      850
#> 3  2013     1     1      542            540         2      923
#> 4  2013     1     1      544            545        -1     1004
#> 5  2013     1     1      554            600        -6      812
#> 6  2013     1     1      554            558        -4      740
#> # . with 836 more rows, and 12 more variables: sched_arr_time <int>,
#> #   arr_delay <dbl>, carrier <chr>, flight <int>, tailnum <chr>,
#> #   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,
#> #   minute <dbl>, time_hour <dttm>

```

###ARRANGE COLUMNS
```{r}
arrange(flights, year, month, day)
#> # A tibble: 336,776 x 19
#>    year month   day dep_time sched_dep_time dep_delay arr_time
#>   <int> <int> <int>    <int>          <int>     <dbl>    <int>
#> 1  2013     1     1      517            515         2      830
#> 2  2013     1     1      533            529         4      850
#> 3  2013     1     1      542            540         2      923
#> 4  2013     1     1      544            545        -1     1004
#> 5  2013     1     1      554            600        -6      812
#> 6  2013     1     1      554            558        -4      740
#> # . with 3.368e+05 more rows, and 12 more variables: sched_arr_time <int>,
#> #   arr_delay <dbl>, carrier <chr>, flight <int>, tailnum <chr>,
#> #   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,
#> #   minute <dbl>, time_hour <dttm>

arrange(flights, desc(dep_delay))
#> # A tibble: 336,776 x 19
#>    year month   day dep_time sched_dep_time dep_delay arr_time
#>   <int> <int> <int>    <int>          <int>     <dbl>    <int>
#> 1  2013     1     9      641            900      1301     1242
#> 2  2013     6    15     1432           1935      1137     1607
#> 3  2013     1    10     1121           1635      1126     1239
#> 4  2013     9    20     1139           1845      1014     1457
#> 5  2013     7    22      845           1600      1005     1044
#> 6  2013     4    10     1100           1900       960     1342
#> # . with 3.368e+05 more rows, and 12 more variables: sched_arr_time <int>,
#> #   arr_delay <dbl>, carrier <chr>, flight <int>, tailnum <chr>,
#> #   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,
#> #   minute <dbl>, time_hour <dttm>

```

###SELECT COLUMNS
```{r}
select(flights, -(year:day))
#> # A tibble: 336,776 x 16
#>   dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay
#>      <int>          <int>     <dbl>    <int>          <int>     <dbl>
#> 1      517            515         2      830            819        11
#> 2      533            529         4      850            830        20
#> 3      542            540         2      923            850        33
#> 4      544            545        -1     1004           1022       -18
#> 5      554            600        -6      812            837       -25
#> 6      554            558        -4      740            728        12
#> # . with 3.368e+05 more rows, and 10 more variables: carrier <chr>,
#> #   flight <int>, tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>,
#> #   distance <dbl>, hour <dbl>, minute <dbl>, time_hour <dttm>

```

###ADD COLUMNS
``` {r}
flights_sml <- select(flights, 
  year:day, 
  ends_with("delay"), 
  distance, 
  air_time
)
mutate(flights_sml,
  gain = dep_delay - arr_delay,
  speed = distance / air_time * 60
)

#OR#
flights_sml <- select(flights, 
  year:day, 
  ends_with("delay"), 
  distance, 
  air_time
)
flights_sml=mutate(flights_sml, 
  gain = dep_delay - arr_delay,
  speed = distance / air_time * 60
)
#> # A tibble: 336,776 x 9
#>    year month   day dep_delay arr_delay distance air_time  gain speed
#>   <int> <int> <int>     <dbl>     <dbl>    <dbl>    <dbl> <dbl> <dbl>
#> 1  2013     1     1         2        11     1400      227    -9  370.
#> 2  2013     1     1         4        20     1416      227   -16  374.
#> 3  2013     1     1         2        33     1089      160   -31  408.
#> 4  2013     1     1        -1       -18     1576      183    17  517.
#> 5  2013     1     1        -6       -25      762      116    19  394.
#> 6  2013     1     1        -4        12      719      150   -16  288.
#> # . with 3.368e+05 more rows

transmute(flights,
  gain = dep_delay - arr_delay,
  hours = air_time / 60,
  gain_per_hour = gain / hours
)
#> # A tibble: 336,776 x 3
#>    gain hours gain_per_hour
#>   <dbl> <dbl>         <dbl>
#> 1    -9  3.78         -2.38
#> 2   -16  3.78         -4.23
#> 3   -31  2.67        -11.6 
#> 4    17  3.05          5.57
#> 5    19  1.93          9.83
#> 6   -16  2.5          -6.4 
#> # . with 3.368e+05 more rows

```

###COLLAPSE DATAFRAME INTO TIBBLE (group_by and summarise)
```{r}
summarise(flights, delay = mean(dep_delay, na.rm = TRUE))
#> # A tibble: 1 x 1
#>   delay
#>   <dbl>
#> 1  12.6

by_day <- group_by(flights, year, month, day) 
summarise(by_day, delay = mean(dep_delay, na.rm = TRUE))
#> # A tibble: 365 x 4
#> # Groups:   year, month [?]
#>    year month   day delay
#>   <int> <int> <int> <dbl>
#> 1  2013     1     1 11.5 
#> 2  2013     1     2 13.9 
#> 3  2013     1     3 11.0 
#> 4  2013     1     4  8.95
#> 5  2013     1     5  5.73
#> 6  2013     1     6  7.15
#> # . with 359 more rows

```


###BASIC STATISTICS
```{r}
#trimmed mean:
#state <- read_csv(file="state.csv") # or read.csv
#mean(state[["Population"]], na.rm = T)
#mean(state[["Population"]], trim=0.1, na.rm = T) # (trim=0.1 drops 10% from each end)

#weighted mean/median for murder rate:
#weighted.mean(state[["Murder.Rate"]], w=state[["Population"]], na.rm = T)
#library("matrixStats")
#weightedMedian(state[["Murder.Rate"]], w=state[["Population"]], na.rm = T)

#sd(state[["Population"]])
#IQR(state[["Population"]])
#mad(state[["Population"]]) #median absolute deviation from the median, more robust i.e. not sensitive to outliers

```

##DATA VISUALIZATION
###SUMMARY STATS
```{r}

#multiple boxplots (pm of east/west on x):
#boxplot(pm25 ~ region, data = pollution, col = "green")

#multiple histograms (one graph on top of another, frequency on y, pm25 of east/west on x):
#par(mfrow = c(2, 1), mar = c(4, 4, 2, 1))
#hist(subset(pollution, region == "east")$pm25, col = "green")
#hist(subset(pollution, region == "west")$pm25, col = "green")

#single scatterplot:
#with(pollution, plot(latitude, pm25, col = region))
#abline(h = 12, lwd = 2, lty = 2)

#multiple scatterplot (three are the same; two graphs next to each other, pm25 on y, latitude on x):
### Regular
#par(mfrow = c(1, 2), mar = c(5, 4, 2, 1))
#with(subset(pollution, region == "west"), plot(latitude, pm25, main = "West"))
#with(subset(pollution, region == "east"), plot(latitude, pm25, main = "East"))

```

###THE BASE SYSTEM (A GRAPHIC SYSTEM): PLOT()
``` {r}
data(cars)

## Create the plot / draw canvas
with(cars, plot(speed, dist))

## Add annotation
title("Speed vs. Stopping distance")
```

###THE LATTICE SYSTEMC(A GRAPHIC SYSTEM)
```{r}
library(lattice)
state <- data.frame(state.x77, region = state.region) #combines the two
xyplot(Life.Exp ~ Income | region, data = state, layout = c(4, 1))
```

###THE GGPLOT SYSTEM (A GRAPHIC SYSTEM)
```{r}
library(ggplot2)
data(mpg)
qplot(displ, hwy, data = mpg, facets = . ~ year)
```

```{r}
ggplot(data = diamonds) +
  geom_bar(mapping = aes(x = cut)) #when categorical
ggplot(data = diamonds) +
  geom_histogram(mapping = aes(x = carat), binwidth = 0.5) #when continuous


ggplot(data = diamonds) +
  geom_count(mapping = aes(x = cut, y = color)) #two categorical
ggplot(data = diamonds) + 
  geom_point(mapping = aes(x = carat, y = price), alpha = 1 / 100) #two continuous


ggplot(data = diamonds, mapping = aes(x = cut, y = price)) +
  geom_boxplot()

ggplot(data = mpg) +
  geom_boxplot(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy)) +
  coord_flip() #coord_flip() flips it 90 degrees clockwise

ggplot(data = diamonds, mapping = aes(x = price)) + 
  geom_freqpoly(mapping = aes(colour = cut), binwidth = 500) #shows count
ggplot(data = diamonds, mapping = aes(x = price, y = ..density..)) + 
  geom_freqpoly(mapping = aes(colour = cut), binwidth = 500) #shows density

```

```{r}
ggplot(diamonds) + 
  geom_histogram(mapping = aes(x = y), binwidth = 0.5) +
  coord_cartesian(ylim = c(0, 50)) #coord_cartesian() zooms into an axis
```

###2 APPROACHES TO PLOTTING
```{r}
##1, if file device
## Open PDF file device; create 'myplot.pdf' in my working directory
pdf(file = "myplot.pdf")  

## Create plot and send to a file (no plot appears on screen)
with(faithful, plot(eruptions, waiting))  

## Annotate plot; still nothing on screen
title(main = "Old Faithful Geyser data")  

## Close the PDF file device
dev.off()  

## Now you can view the file 'myplot.pdf' on your computer

##2, if screen device
## Create plot on screen device
with(faithful, plot(eruptions, waiting))  

## Annotate with a title
title(main = "Old Faithful Geyser data")   

## Copy my plot to a PNG file device
dev.copy(png, file = "geyserplot.png")  

## Close the PNG file device
dev.off() 
  
```

##K-MEANS CLUSTERING
###CREATE THE CLUSTERS
```{r}
set.seed(1234)
x <- rnorm(12, mean = rep(1:3, each = 4), sd = 0.2)
y <- rnorm(12, mean = rep(c(1, 2, 1), each = 4), sd = 0.2)

dataFrame <- data.frame(x, y)
kmeansObj <- kmeans(dataFrame, centers = 3) #3 is the specified number of clusters
names(kmeansObj) 
kmeansObj$cluster #shows assignment of the cluster of each data point
```

###BUILD HEATMAP
```{r}
set.seed(1234)
dataMatrix <- as.matrix(dataFrame)[sample(1:12), ]
kmeansObj <- kmeans(dataMatrix, centers = 3)

par(mfrow = c(1, 2))
image(t(dataMatrix)[, nrow(dataMatrix):1], yaxt = "n", main = "Original Data")
image(t(dataMatrix)[, order(kmeansObj$cluster)], yaxt = "n", main = "Clustered Data")

```

##PCA
###COMPUTE THE PRINCIPAL COMPONENTS
```{r}
mtcars.pca <- prcomp(mtcars[,c(1:7,10,11)], center = TRUE,scale. = TRUE)
summary(mtcars.pca) #PC1 explains 63% of the total variance (P2 explains 23%)
str(mtcars.pca) #contains 1) the center point ($center), scaling ($scale), standard deviation($sdev) of each PC; 2) the relationship (correlation, anticorrelation, etc) between the initial variables and the PCs; 3) the values of each data point in terms of the PCs ($x)

```

###PLOT THE PCA
```{r}
# source: https://www.datacamp.com/community/tutorials/pca-analysis-r
#library(devtools)
#install_github("vqv/ggbiplot")

#library(ggbiplot)
#ggbiplot(mtcars.pca) #variables hp, cyl, and disp are all contributors to PC1
#ggbiplot(mtcars.pca, labels=rownames(mtcars)) #Maserati Bora, Ferrari Dino and Ford Pantera L cluster together

#mtcars.country <- c(rep("Japan", 3), rep("US",4), rep("Europe", 7),rep("US",3), "Europe", rep("Japan", 3), rep("US",4), rep("Europe", 3), "US", rep("Europe", 3))
#ggbiplot(mtcars.pca, ellipse=TRUE, labels=rownames(mtcars), groups=mtcars.country) #American cars are characterized by high values for cyl, disp, and wt. Japanese cars are characterized by high mpg. European cars are less tightly clustered.

#ggbiplot(mtcars.pca, ellipse=TRUE, obs.scale = 1, var.scale = 1,var.axes=FALSE, labels=rownames(mtcars), groups=mtcars.country) #scale the samples (obs.scale) and the variables (var.scale), and remove the arrows altogether (var.axes)

#ggbiplot(mtcars.pca,ellipse=TRUE,obs.scale = 1, var.scale = 1,  labels=rownames(mtcars), groups=mtcars.country) +
  #scale_colour_manual(name="Origin", values= c("forest green", "red3", "dark blue"))+
  #ggtitle("PCA of mtcars dataset")+
  #theme_minimal()+ #the minimal theme
  #theme(legend.position = "bottom")

```




